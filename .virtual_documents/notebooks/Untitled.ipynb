import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report


# Load dataset
df = pd.read_csv("../data/rbt_turnover_data.csv")


# Drop non-relevant columns
df.drop(columns=["rbt_id"], inplace=True)


# Convert education_level into numeric values
education_mapping = {
    "High School": 1,
    "Associate's": 2,
    "Bachelor's": 3,
    "Master's": 4,
    "Doctorate": 5
}
df["education_level_encoded"] = df["education_level"].map(education_mapping)

# Drop the original categorical column
df.drop(columns=["education_level"], inplace=True)


# Define features (X) and target variable (y)
X = df.drop(columns=["turnover_status"])
y = df["turnover_status"]


# Split data (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("âœ… Data split complete!")
print(f"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}")


# Correlation heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, fmt=".2f", cmap="coolwarm", linewidths=0.5, vmin=-1, vmax=1)
plt.title("Feature Correlation Heatmap")
plt.show()


from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Train the model with class balancing
log_reg = LogisticRegression(class_weight="balanced", max_iter=1000)
log_reg.fit(X_train, y_train)

# Make predictions
y_pred = log_reg.predict(X_test)

# Evaluate model performance
print(f"ðŸ” Logistic Regression Accuracy: {accuracy_score(y_test, y_pred):.2f}")
print(classification_report(y_test, y_pred, zero_division=1))


# Get probability predictions
y_probs = log_reg.predict_proba(X_test)[:, 1]

# Change threshold from 0.5 to 0.3
y_pred_adjusted = (y_probs > 0.3).astype(int)

# Evaluate the adjusted model
print("ðŸ” Logistic Regression with Adjusted Threshold (0.3):")
print(classification_report(y_test, y_pred_adjusted, zero_division=1))


from sklearn.ensemble import RandomForestClassifier

# Train Random Forest with class balancing
rf_model = RandomForestClassifier(n_estimators=100, class_weight="balanced", random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions
y_pred_rf = rf_model.predict(X_test)

# Evaluate performance
print(f"ðŸŒ² Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf):.2f}")
print(classification_report(y_test, y_pred_rf, zero_division=1))


# Extract feature importance
feature_importances = rf_model.feature_importances_
feat_importance_df = pd.DataFrame({"Feature": X.columns, "Importance": feature_importances}).sort_values(by="Importance", ascending=False)

# Plot feature importance with proper hue assignment
plt.figure(figsize=(10, 6))
sns.barplot(x="Importance", y="Feature", hue="Feature", data=feat_importance_df, palette="viridis", legend=False)

# Title without emoji (fix for glyph issue)
plt.title("Feature Importance for RBT Turnover Prediction")

plt.show()


# Check class distribution
print(df["turnover_status"].value_counts(normalize=True))

# Visualize class distribution
plt.figure(figsize=(6,4))
sns.countplot(x="turnover_status", data=df, palette="pastel")
plt.title("Turnover Status Distribution (Before Balancing)")
plt.xlabel("Turnover Status (0 = Stayed, 1 = Left)")
plt.ylabel("Count")
plt.show()


from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

# Define features (X) and target variable (y)
X = df.drop(columns=["turnover_status"])
y = df["turnover_status"]

# Split dataset before applying SMOTE
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Apply SMOTE only on training data
smote = SMOTE(sampling_strategy="auto", random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

# Check new class distribution
print("ðŸ”„ After SMOTE Balancing:")
print(pd.Series(y_train_balanced).value_counts(normalize=True))


from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Train Random Forest with balanced dataset
rf_model_balanced = RandomForestClassifier(n_estimators=100, class_weight="balanced", random_state=42)
rf_model_balanced.fit(X_train_balanced, y_train_balanced)

# Make predictions on test set
y_pred_rf_balanced = rf_model_balanced.predict(X_test)

# Evaluate the model
print(f"ðŸŒ² Balanced Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf_balanced):.2f}")
print(classification_report(y_test, y_pred_rf_balanced, zero_division=1))


from xgboost import XGBClassifier

# Train XGBoost Model
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric="logloss", scale_pos_weight=2)  # Adjust weight for turnover class
xgb_model.fit(X_train_balanced, y_train_balanced)

# Make predictions
y_pred_xgb = xgb_model.predict(X_test)

# Evaluate performance
print(f"ðŸš€ XGBoost Accuracy: {accuracy_score(y_test, y_pred_xgb):.2f}")
print(classification_report(y_test, y_pred_xgb, zero_division=1))



from xgboost import XGBClassifier

# Train XGBoost Model with Tuned Parameters
xgb_model_tuned = XGBClassifier(
    use_label_encoder=False, 
    eval_metric="logloss",
    scale_pos_weight=2,  # Adjust weight for turnover class
    n_estimators=300,  # Increase number of trees
    max_depth=6,  # Limit depth to prevent overfitting
    learning_rate=0.1,  # Adjust learning rate
    colsample_bytree=0.8,  # Reduce features per tree
    subsample=0.8  # Reduce sample size per tree
)

xgb_model_tuned.fit(X_train_balanced, y_train_balanced)

# Make predictions
y_pred_xgb_tuned = xgb_model_tuned.predict(X_test)

# Evaluate performance
print(f"ðŸš€ Tuned XGBoost Accuracy: {accuracy_score(y_test, y_pred_xgb_tuned):.2f}")
print(classification_report(y_test, y_pred_xgb_tuned, zero_division=1))


import numpy as np

# Get predicted probabilities instead of hard classifications
y_prob_xgb = xgb_model_tuned.predict_proba(X_test)[:, 1]  # Probability of class 1 (turnover)

# Adjust threshold (default is 0.5, try lowering it)
threshold = 0.4  # Experiment with different values (e.g., 0.3, 0.35, 0.4)
y_pred_xgb_adj = np.where(y_prob_xgb > threshold, 1, 0)

# Evaluate new threshold
print(f"ðŸš€ XGBoost with Adjusted Threshold ({threshold}):")
print(classification_report(y_test, y_pred_xgb_adj, zero_division=1))





from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred_xgb_adj)

# Display confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Stayed (0)", "Left (1)"])
disp.plot(cmap="Blues")
plt.title("Confusion Matrix - XGBoost (Adjusted Threshold 0.4)")
plt.show()




